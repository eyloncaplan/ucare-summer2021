{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#very preliminary attempt at making the IE DenseNet model into a class\n",
    "class IntegralDenseNet:\n",
    "    def __init__(self, learning_rate=0.01, leakyRelU_weight=0.1, optimizer=None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.leakyRelU_weight = leakyRelU_weight\n",
    "        self.optimizer = tf.keras.optimizers.Adam(self.learning_rate) if optimizer is None else optimizer\n",
    "    def prepTF(x):\n",
    "        #converts numpy array to tensor and adds dimension to the front\n",
    "        return tf.expand_dims((tf.convert_to_tensor(x, dtype=tf.float32), 0))                \n",
    "    def fit(self, X, y, t0): #X has shape (batch, spatial shape, channels)\n",
    "        self.t1 = t0+1\n",
    "        self.filter_shape = (self.t1, *X.shape, 1) #time steps, spatial shape, in-channels, out-channels\n",
    "        self.input_shape = (1, *X.shape) #batch size,(1), input spatial shape, in-channels\n",
    "\n",
    "        rng = np.random.default_rng()\n",
    "        iFilt = rng.standard_normal(self.filter_shape, dtype=np.float32)\n",
    "        paramFilt = rng.standard_normal((self.t1,*self.filter_shape), dtype=np.float32) #layer from, layer to, spatial shape, in-channels, out-channels\n",
    "        biasVec = rng.standard_normal((self.t1,1), dtype=np.float32)\n",
    "\n",
    "        TFiFiltTensor = tf.compat.v1.get_variable(\"iFiltTensor\", initializer=iFilt)\n",
    "        self.iFilt = tf.Variable(TFiFiltTensor, name=\"iFilt\")\n",
    "        TFpFiltTensor = tf.compat.v1.get_variable(\"pFiltTensor\", initializer=paramFilt)\n",
    "        self.pFilt = tf.Variable(TFpFiltTensor, name=\"pFilt\")\n",
    "        self.b = tf.compat.v1.get_variable(\"biasVec\", initializer=biasVec)\n",
    "        \n",
    "        model = (self.iFilt, self.pFilt, self.b)\n",
    "        \n",
    "        for i in np.arange(len(y)):\n",
    "            tf_x = prepTF(X[i].astype(np.float32))\n",
    "            tf_y = prepTF(y[i].astype(np.float32))\n",
    "            optimize(self.optimizer, tf_x, *model, tf_y)   \n",
    "    def trapezoidIntegral(vals, ds):\n",
    "        pass1 = tf.reduce_sum(vals, axis=0)\n",
    "        pass2 = tf.reduce_sum(vals[1:-1], axis=0)\n",
    "        return ds/2.0*(pass1+pass2)\n",
    "    def TFconv(image, filt, b):\n",
    "        return tf.nn.convolution(input=image, filters=filt, padding=\"SAME\") + b\n",
    "    def leakyRelUInv(x):\n",
    "        shape = x.shape\n",
    "        zeros = tf.zeros(shape)\n",
    "        mask = tf.math.greater_equal(x, zeros)\n",
    "        weighted = x / leakyRelU_weight\n",
    "        return tf.where(mask, x, weighted)\n",
    "    def feedForward(self, x0, tape): #ideally this will only produce the output and will be tracked by the tape\n",
    "        t1 = inFilt.shape[0]\n",
    "        ds = 1.0/(t1-1)\n",
    "        input_shape = x0.shape\n",
    "        bzero = tf.zeros([inFilt.shape[4]])\n",
    "        x = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)\n",
    "        u = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)\n",
    "\n",
    "        tape.watch(x0)\n",
    "        u0 = leakyRelUInv(x0)\n",
    "        u = u.write(0,TFconv(u0, inFilt[0], bzero))\n",
    "\n",
    "        for h in range(t1-1):\n",
    "            x = x.write(h, tf.nn.leaky_relu(u.read(h), alpha=leakyRelU_weight))\n",
    "            zInt = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "            for s in range(h+1):\n",
    "                zInt = zInt.write(s, TFconv(x.read(s), pFilt[s,h], b[h] / ((h+1)*ds)))\n",
    "            z = trapezoidIntegral(zInt.stack(), ds)\n",
    "            u = u.write(h+1, z + TFconv(u0, inFilt[h+1], bzero))\n",
    "        x = x.write(t1-1,tf.nn.leaky_relu(u.read(t1-1), alpha=leakyRelU_weight))\n",
    "\n",
    "        loss = tf.math.square(x.read(t1-1) - y)\n",
    "        gradients = tape.gradient(loss, [pFilt, inFilt, b])\n",
    "\n",
    "        return x.read(t1-1), tf.math.reduce_sum(loss), gradients\n",
    "    def optimize(optimizer, xIn, y): #ideally this can be called only when descending gradient, and feedForward can be called for output\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = TFuSoln(xIn, tape)\n",
    "            loss = tf.math.square(output - y)\n",
    "            gradients = tape.gradient(loss, [pFilt, inFilt, b])\n",
    "            \n",
    "        optimizer.apply_gradients(zip(grad, [pFilt, iFilt, bias]))\n",
    "        return loss\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFuSoln = tf.function(uSoln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "nn = IntegralDenseNet()\n",
    "X = np.random.random((10,5,5,1))\n",
    "y = np.random.random((10,5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "leakyRelU_weight = 0.1\n",
    "opt = tf.keras.optimizers.Adam(learning_rate)\n",
    "input_shape = (1,5,5)\n",
    "filter_shape = (1,1,3,3)\n",
    "t0 = 5\n",
    "\n",
    "model = make_model(t0, input_shape, filter_shape)\n",
    "y = prepped_output(np.random.rand(*input_shape).astype(np.float32))\n",
    "\n",
    "\n",
    "iterations = 1\n",
    "losses = []\n",
    "for i in np.arange(iterations):\n",
    "    npx, npy = make_xy_pair(input_shape)\n",
    "    x = prepped_input(npx.astype(np.float32))\n",
    "    y = prepped_output(npy.astype(np.float32))\n",
    "    losses.append(optimize(opt, x, *model, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
